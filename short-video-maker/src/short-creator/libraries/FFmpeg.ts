import ffmpeg from "fluent-ffmpeg";
import { Readable } from "node:stream";
import { spawn } from "child_process";
import path from "path";
import fs from "fs-extra";
import { logger } from "../../logger";
import { OrientationEnum } from "../../types/shorts";
import type { RenderConfig } from "../../types/shorts";

// Font paths to check (in order of preference)
const FONT_PATHS = [
  // Docker/Cloud Run paths (fonts-nanum package)
  '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf',
  '/usr/share/fonts/truetype/nanum/NanumGothic-Bold.ttf',
  // Local development paths
  '/home/akfldk1028/.fonts/NanumGothic-Bold.ttf',
  // Fallback to DejaVu Sans (commonly available)
  '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf',
  // Ubuntu/Debian default fonts
  '/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf',
];

// Cache the found font path
let cachedFontPath: string | null = null;

/**
 * Find the first available font path from the list of candidates
 */
function findAvailableFontPath(): string {
  if (cachedFontPath) {
    return cachedFontPath;
  }

  for (const fontPath of FONT_PATHS) {
    if (fs.existsSync(fontPath)) {
      logger.info({ fontPath }, "Found available font for captions");
      cachedFontPath = fontPath;
      return fontPath;
    }
  }

  // If no font found, log warning and return first path (will fail gracefully)
  logger.warn({ triedPaths: FONT_PATHS }, "No font file found for captions, subtitles may not render");
  return FONT_PATHS[0];
}

export class FFMpeg {
  static async init(): Promise<FFMpeg> {
    return import("@ffmpeg-installer/ffmpeg").then((ffmpegInstaller) => {
      ffmpeg.setFfmpegPath(ffmpegInstaller.path);
      logger.info(`FFmpeg path set to: ${ffmpegInstaller.path}`);
      // Log the font path that will be used
      const fontPath = findAvailableFontPath();
      logger.info(`Caption font path: ${fontPath}`);
      return new FFMpeg();
    });
  }

  async saveNormalizedAudio(
    audio: ArrayBuffer,
    outputPath: string,
  ): Promise<string> {
    logger.debug("Normalizing audio for Whisper");
    const inputStream = new Readable();
    inputStream.push(Buffer.from(audio));
    inputStream.push(null);

    return new Promise((resolve, reject) => {
      ffmpeg()
        .input(inputStream)
        .audioCodec("pcm_s16le")
        .audioChannels(1)
        .audioFrequency(16000)
        .toFormat("wav")
        .on("end", () => {
          logger.debug("Audio normalization complete");
          resolve(outputPath);
        })
        .on("error", (error: unknown) => {
          logger.error(error, "Error normalizing audio:");
          reject(error);
        })
        .save(outputPath);
    });
  }

  async createMp3DataUri(audio: ArrayBuffer): Promise<string> {
    const inputStream = new Readable();
    inputStream.push(Buffer.from(audio));
    inputStream.push(null);
    return new Promise((resolve, reject) => {
      const chunk: Buffer[] = [];

      ffmpeg()
        .input(inputStream)
        .audioCodec("libmp3lame")
        .audioBitrate(128)
        .audioChannels(2)
        .toFormat("mp3")
        .on("error", (err) => {
          reject(err);
        })
        .pipe()
        .on("data", (data: Buffer) => {
          chunk.push(data);
        })
        .on("end", () => {
          const buffer = Buffer.concat(chunk);
          resolve(`data:audio/mp3;base64,${buffer.toString("base64")}`);
        })
        .on("error", (err) => {
          reject(err);
        });
    });
  }

  async saveToMp3(audio: ArrayBuffer, filePath: string): Promise<string> {
    const inputStream = new Readable();
    inputStream.push(Buffer.from(audio));
    inputStream.push(null);
    return new Promise((resolve, reject) => {
      ffmpeg()
        .input(inputStream)
        .audioCodec("libmp3lame")
        .audioBitrate(128)
        .audioChannels(2)
        .toFormat("mp3")
        .save(filePath)
        .on("end", () => {
          logger.debug("Audio conversion complete");
          resolve(filePath);
        })
        .on("error", (err) => {
          reject(err);
        });
    });
  }

  async combineVideoWithAudioAndCaptions(
    videoPath: string,
    audioPath: string,
    captions: any[],
    outputPath: string,
    durationSeconds: number,
    orientation: OrientationEnum,
    config: RenderConfig,
    skipSubtitles = false // ë©€í‹°ì”¬ì—ì„œ ê°œë³„ ì”¬ ì²˜ë¦¬ì‹œ ìë§‰ ê±´ë„ˆë›°ê¸°
  ): Promise<string> {
    logger.debug({ videoPath, audioPath, outputPath }, "Combining video with audio using FFmpeg");

    return new Promise((resolve, reject) => {
      const ffmpegCommand = ffmpeg()
        .input(videoPath)
        .input(audioPath)
        .videoCodec('libx264')
        .audioCodec('aac')
        .fps(30); // Normalize to 30fps to ensure consistent frame rate for concatenation

      // Add subtitle filter for captions if available (unless skipped for multi-scene)
      if (!skipSubtitles && captions && captions.length > 0) {
        const subtitleFilter = this.createSubtitleFilter(captions, orientation);
        if (subtitleFilter) {
          // Use complex filter for subtitles
          ffmpegCommand.complexFilter(`[0:v]${subtitleFilter}[v]`);
          ffmpegCommand.outputOptions([
            '-map', '[v]',    // Use filtered video
            '-map', '1:a:0',  // Use audio from second input
            '-shortest',      // Stop when shortest input ends
            `-t ${durationSeconds}` // Set duration
          ]);
        } else {
          // No subtitle filter, use simple mapping
          ffmpegCommand.outputOptions([
            '-map', '0:v:0',  // Use video from first input
            '-map', '1:a:0',  // Use audio from second input
            '-shortest',      // Stop when shortest input ends
            `-t ${durationSeconds}` // Set duration
          ]);
        }
      } else {
        // No subtitle, use simple mapping
        ffmpegCommand.outputOptions([
          '-map', '0:v:0',  // Use video from first input
          '-map', '1:a:0',  // Use audio from second input
          '-shortest',      // Stop when shortest input ends
          `-t ${durationSeconds}` // Set duration
        ]);
      }

      ffmpegCommand
        .on('end', () => {
          logger.debug({ outputPath }, "Video combination complete");
          resolve(outputPath);
        })
        .on('error', (error: any) => {
          logger.error(error, "Error combining video with audio");
          reject(error);
        })
        .save(outputPath);
    });
  }

  /**
   * ğŸ”¥ TikTok/Shorts ìŠ¤íƒ€ì¼ ìë§‰ í•„í„° ìƒì„±
   *
   * ë‹¨ì–´ë³„ í•˜ì´ë¼ì´íŠ¸ íš¨ê³¼:
   * - ì—¬ëŸ¬ ë‹¨ì–´ë¥¼ í•¨ê»˜ í‘œì‹œ
   * - í˜„ì¬ ë°œí™”ì¤‘ì¸ ë‹¨ì–´ë§Œ ë…¸ë€ìƒ‰ í•˜ì´ë¼ì´íŠ¸
   * - fontcolor_exprë¡œ ì‹œê°„ ê¸°ë°˜ ìƒ‰ìƒ ë³€ê²½
   */
  private createSubtitleFilter(captions: any[], orientation: OrientationEnum): string | null {
    try {
      if (!captions || captions.length === 0) return null;

      // ğŸ”¥ TikTok/Shorts ìŠ¤íƒ€ì¼ ì„¤ì •
      const fontSize = orientation === OrientationEnum.portrait ? 52 : 60; // ë” í¬ê²Œ!
      const yPosition = orientation === OrientationEnum.portrait ? 'h*0.72' : 'h*0.78'; // Shorts ì•ˆì „ ì˜ì—­

      // Dynamic font path (works in both local and Docker/Cloud Run)
      const fontPath = findAvailableFontPath();

      // ğŸ”¥ TikTok ìŠ¤íƒ€ì¼ ìƒ‰ìƒ
      const normalColor = 'FFFFFF'; // í°ìƒ‰ (ë¹„í™œì„±)
      const highlightColor = 'FFEB3B'; // ë…¸ë€ìƒ‰ (í™œì„±)
      const borderColor = 'black';
      const borderWidth = 4;

      // ë‹¨ì–´ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê¸° (2-3 ë‹¨ì–´ì”©)
      const wordGroups = this.groupWordsForDisplay(captions, 3);

      const drawTextFilters: string[] = [];

      wordGroups.forEach((group, groupIndex) => {
        const groupStartTime = group[0].startMs / 1000;
        const groupEndTime = group[group.length - 1].endMs / 1000;

        // ê·¸ë£¹ ë‚´ ê° ë‹¨ì–´ì— ëŒ€í•´ drawtext ìƒì„±
        group.forEach((word, wordIndex) => {
          const wordStartTime = word.startMs / 1000;
          const wordEndTime = word.endMs / 1000;

          // ë‹¨ì–´ í…ìŠ¤íŠ¸ escape ë° ëŒ€ë¬¸ì ë³€í™˜
          const text = word.text.replace(/'/g, "'\\\\\\''").replace(/:/g, '\\:').toUpperCase();

          // ë‹¨ì–´ì˜ x ìœ„ì¹˜ ê³„ì‚° (ê·¸ë£¹ ë‚´ ìœ„ì¹˜ì— ë”°ë¼)
          // ê°„ë‹¨í•œ ë°©ë²•: ì´ì „ ë‹¨ì–´ë“¤ì˜ ë„ˆë¹„ ì¶”ì •
          const wordsBefore = group.slice(0, wordIndex).map(w => w.text.toUpperCase()).join(' ');

          // ğŸ”¥ í•µì‹¬: fontcolor_exprë¡œ ì‹œê°„ ê¸°ë°˜ ìƒ‰ìƒ ë³€ê²½
          // í˜„ì¬ ë‹¨ì–´ê°€ ë°œí™” ì¤‘ì´ë©´ ë…¸ë€ìƒ‰, ì•„ë‹ˆë©´ í°ìƒ‰
          const fontcolorExpr = `if(between(t\\,${wordStartTime}\\,${wordEndTime})\\,0x${highlightColor}\\,0x${normalColor})`;

          // x ìœ„ì¹˜: ì¤‘ì•™ ì •ë ¬ ê¸°ì¤€ìœ¼ë¡œ ì˜¤í”„ì…‹ ê³„ì‚°
          // ê·¸ë£¹ ì „ì²´ í…ìŠ¤íŠ¸ì˜ ì¤‘ì•™ì—ì„œ ê° ë‹¨ì–´ ìœ„ì¹˜ ê³„ì‚°
          const fullGroupText = group.map(w => w.text.toUpperCase()).join(' ');
          const xPosition = wordIndex === 0
            ? `(w-text_w*${fullGroupText.length/text.length})/2`
            : `(w-text_w*${fullGroupText.length/text.length})/2+text_w*${wordsBefore.length/text.length}`;

          drawTextFilters.push(
            `drawtext=fontfile=${fontPath}:` +
            `text='${text} ':` + // ê³µë°± ì¶”ê°€ë¡œ ë‹¨ì–´ ê°„ê²©
            `fontcolor_expr=${fontcolorExpr}:` +
            `fontsize=${fontSize}:` +
            `x=(w-tw)/2:` + // ê°„ë‹¨íˆ ì¤‘ì•™ ì •ë ¬ (ë³µì¡í•œ ìœ„ì¹˜ ê³„ì‚° ëŒ€ì‹ )
            `y=${yPosition}:` +
            `borderw=${borderWidth}:` +
            `bordercolor=${borderColor}:` +
            `enable=between(t\\,${groupStartTime}\\,${groupEndTime})`
          );
        });
      });

      // ë„ˆë¬´ ë§ì€ í•„í„°ëŠ” ì„±ëŠ¥ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥
      // ë‹¨ìˆœí™”: ë‹¨ì–´ë³„ ê°œë³„ í‘œì‹œ (í•˜ì´ë¼ì´íŠ¸ ìƒ‰ìƒ ì ìš©)
      if (drawTextFilters.length > 50) {
        return this.createSimplifiedSubtitleFilter(captions, orientation);
      }

      return drawTextFilters.join(',');
    } catch (error) {
      logger.warn(error, "Could not create subtitle filter, falling back to simplified version");
      return this.createSimplifiedSubtitleFilter(captions, orientation);
    }
  }

  /**
   * ë‹¨ì–´ ê·¸ë£¹í™” (nê°œì”© ë¬¶ê¸°)
   */
  private groupWordsForDisplay(captions: any[], maxWordsPerGroup: number): any[][] {
    const groups: any[][] = [];
    let currentGroup: any[] = [];

    captions.forEach((caption, index) => {
      currentGroup.push(caption);

      // ê·¸ë£¹ì´ ê½‰ ì°¼ê±°ë‚˜, ë‹¤ìŒ ë‹¨ì–´ì™€ ì‹œê°„ ì°¨ì´ê°€ í¬ë©´ ìƒˆ ê·¸ë£¹
      const nextCaption = captions[index + 1];
      const timegap = nextCaption ? (nextCaption.startMs - caption.endMs) : 9999;

      if (currentGroup.length >= maxWordsPerGroup || timegap > 500) {
        groups.push([...currentGroup]);
        currentGroup = [];
      }
    });

    if (currentGroup.length > 0) {
      groups.push(currentGroup);
    }

    return groups;
  }

  /**
   * ğŸ”¥ ê°„ì†Œí™”ëœ TikTok ìŠ¤íƒ€ì¼ ìë§‰ í•„í„° (ë‹¨ì–´ í•˜ë‚˜ì”© ë…¸ë€ìƒ‰)
   */
  private createSimplifiedSubtitleFilter(captions: any[], orientation: OrientationEnum): string | null {
    try {
      if (!captions || captions.length === 0) return null;

      const fontSize = orientation === OrientationEnum.portrait ? 56 : 64;
      const yPosition = orientation === OrientationEnum.portrait ? 'h*0.72' : 'h*0.78';
      // Dynamic font path (works in both local and Docker/Cloud Run)
      const fontPath = findAvailableFontPath();

      // ğŸ”¥ ë…¸ë€ìƒ‰ í•˜ì´ë¼ì´íŠ¸ (TikTok ìŠ¤íƒ€ì¼)
      const fontColor = 'FFEB3B'; // ë…¸ë€ìƒ‰!
      const borderColor = 'black';
      const borderWidth = 5;
      const shadowColor = 'black@0.7';

      const drawTextFilters = captions.map((caption) => {
        const startTime = caption.startMs / 1000;
        const endTime = caption.endMs / 1000;
        const text = caption.text.replace(/'/g, "'\\\\\\''").replace(/:/g, '\\:').toUpperCase();

        return `drawtext=fontfile=${fontPath}:text='${text}':fontcolor=0x${fontColor}:fontsize=${fontSize}:x=(w-text_w)/2:y=${yPosition}:borderw=${borderWidth}:bordercolor=${borderColor}:shadowcolor=${shadowColor}:shadowx=3:shadowy=3:enable=between(t\\,${startTime}\\,${endTime})`;
      });

      return drawTextFilters.join(',');
    } catch (error) {
      logger.warn(error, "Could not create simplified subtitle filter");
      return null;
    }
  }

  /**
   * Trim video to specified duration
   * Useful for trimming VEO3 videos (min 6s) to match shorter audio lengths
   */
  async trimVideo(inputPath: string, outputPath: string, duration: number): Promise<void> {
    logger.debug({ inputPath, outputPath, duration }, "Trimming video with FFmpeg");

    return new Promise((resolve, reject) => {
      ffmpeg(inputPath)
        .setDuration(duration)
        .outputOptions(['-c', 'copy']) // Copy without re-encoding for speed
        .on('start', (commandLine) => {
          logger.debug('FFmpeg trim command: ' + commandLine);
        })
        .on('end', () => {
          logger.debug({ outputPath, duration }, "Video trim complete");
          resolve();
        })
        .on('error', (err) => {
          logger.error({ error: err, inputPath, outputPath }, "FFmpeg video trim failed");
          reject(err);
        })
        .save(outputPath);
    });
  }

  /**
   * ì—¬ëŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ì„ FFmpeg concat demuxerë¡œ ê²°í•©
   * ë¬´ì†ì‹¤ ê²°í•©ì„ ìœ„í•´ concat demuxer ì‚¬ìš© (ì¬ì¸ì½”ë”© ì—†ìŒ)
   * Cloud Run í˜¸í™˜ì„±ì„ ìœ„í•´ spawn ì‚¬ìš© (fluent-ffmpeg mergeToFileì´ hangë¨)
   */
  async concatVideos(inputPaths: string[], outputPath: string): Promise<string> {
    logger.info({ inputPaths, outputPath }, "Concatenating videos with FFmpeg spawn");

    if (inputPaths.length === 0) {
      throw new Error("No input paths provided");
    }

    if (inputPaths.length === 1) {
      // ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš° ë³µì‚¬ë§Œ ìˆ˜í–‰
      fs.copyFileSync(inputPaths[0], outputPath);
      return outputPath;
    }

    // concat demuxerìš© íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    const concatListPath = path.join(path.dirname(outputPath), `concat_list_${Date.now()}.txt`);
    const concatListContent = inputPaths.map(p => `file '${p}'`).join('\n');
    fs.writeFileSync(concatListPath, concatListContent);

    logger.debug({ concatListPath, concatListContent }, "Created concat list file");

    try {
      // FFmpeg concat demuxerë¡œ ë¹„ë””ì˜¤ ê²°í•© (ì¬ì¸ì½”ë”© ì—†ìŒ)
      await this.runFFmpegSpawn([
        '-f', 'concat',
        '-safe', '0',
        '-i', concatListPath,
        '-c', 'copy',
        '-y',
        outputPath
      ], 300000); // 5ë¶„ íƒ€ì„ì•„ì›ƒ

      logger.info({ outputPath }, "Video merge complete via spawn");
      return outputPath;
    } finally {
      // concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
      try {
        fs.unlinkSync(concatListPath);
      } catch (cleanupError) {
        logger.warn({ cleanupError }, "Could not clean up concat list file");
      }
    }
  }

  /**
   * FFmpeg ëª…ë ¹ì„ spawnìœ¼ë¡œ ì‹¤í–‰ (Cloud Run í˜¸í™˜)
   * fluent-ffmpegê°€ hangë˜ëŠ” ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì§ì ‘ spawn ì‚¬ìš©
   */
  private runFFmpegSpawn(args: string[], timeoutMs: number): Promise<string> {
    return new Promise(async (resolve, reject) => {
      let stdout = '';
      let stderr = '';
      let killed = false;

      // FFmpeg ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
      const ffmpegInstaller = await import("@ffmpeg-installer/ffmpeg");
      const ffmpegPath = ffmpegInstaller.path;

      logger.debug({ ffmpegPath, args, timeoutMs }, "Starting FFmpeg spawn process");

      const process = spawn(ffmpegPath, args, {
        stdio: ['ignore', 'pipe', 'pipe']
      });

      const timer = setTimeout(() => {
        killed = true;
        process.kill('SIGKILL');
        reject(new Error(`FFmpeg process timed out after ${timeoutMs}ms`));
      }, timeoutMs);

      process.stdout?.on('data', (data) => {
        stdout += data.toString();
      });

      process.stderr?.on('data', (data) => {
        stderr += data.toString();
        // FFmpegëŠ” ì§„í–‰ ìƒí™©ì„ stderrë¡œ ì¶œë ¥
        if (stderr.includes('frame=') || stderr.includes('time=')) {
          logger.debug({ progress: stderr.slice(-200) }, "FFmpeg progress");
        }
      });

      process.on('close', (code) => {
        clearTimeout(timer);
        if (killed) return;

        if (code === 0) {
          resolve(stdout);
        } else {
          logger.error({ code, stderr: stderr.slice(-500), stdout }, "FFmpeg process failed");
          reject(new Error(`FFmpeg process exited with code ${code}: ${stderr.slice(-500)}`));
        }
      });

      process.on('error', (error) => {
        clearTimeout(timer);
        logger.error({ error }, "FFmpeg spawn error");
        reject(new Error(`Failed to spawn FFmpeg process: ${error.message}`));
      });
    });
  }

  async concatAudios(inputPaths: string[], outputPath: string): Promise<string> {
    logger.debug({ inputPaths, outputPath }, "Concatenating audio files with FFmpeg");

    return new Promise(async (resolve, reject) => {
      try {
        if (inputPaths.length === 0) {
          reject(new Error("No audio input paths provided"));
          return;
        }

        if (inputPaths.length === 1) {
          // ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš° ë³µì‚¬ë§Œ ìˆ˜í–‰
          fs.copyFileSync(inputPaths[0], outputPath);
          resolve(outputPath);
          return;
        }

        // fluent-ffmpeg concat filter ì‚¬ìš©
        let ffmpegCommand = ffmpeg();

        // ëª¨ë“  ì…ë ¥ íŒŒì¼ ì¶”ê°€
        for (const inputPath of inputPaths) {
          ffmpegCommand = ffmpegCommand.input(inputPath);
        }

        // concat filter ì„¤ì • (audio only)
        const filterComplex = inputPaths.map((_, i) => `[${i}:a]`).join('') +
                             `concat=n=${inputPaths.length}:v=0:a=1[outa]`;

        ffmpegCommand
          .complexFilter(filterComplex)
          .outputOptions('-map', '[outa]')
          .audioCodec('libmp3lame')
          .audioBitrate('192k')
          .on('start', (commandLine) => {
            logger.debug('FFmpeg audio concat command: ' + commandLine);
          })
          .on('progress', (progress) => {
            logger.debug(`Audio concat progress: ${Math.floor(progress.percent || 0)}% done`);
          })
          .on('end', () => {
            logger.debug({ outputPath }, "Audio concatenation complete");
            resolve(outputPath);
          })
          .on('error', (error) => {
            logger.error(error, "FFmpeg audio concatenation failed");
            reject(error);
          })
          .save(outputPath);

      } catch (error) {
        logger.error(error, "Error setting up FFmpeg audio concatenation");
        reject(error);
      }
    });
  }


  /**
   * ê¸°ì¡´ ë¹„ë””ì˜¤ì— ì‹œê°„ ë™ê¸°í™”ëœ ìë§‰ ì¶”ê°€ (ë©€í‹°ì”¬ìš©)
   */
  async addSubtitlesToVideo(
    inputVideoPath: string,
    outputVideoPath: string,
    captions: any[],
    orientation: OrientationEnum
  ): Promise<string> {
    logger.debug({ inputVideoPath, outputVideoPath, captionCount: captions.length }, "Adding synchronized subtitles to video");

    return new Promise((resolve, reject) => {
      const ffmpegCommand = ffmpeg()
        .input(inputVideoPath)
        .videoCodec('libx264')
        .audioCodec('aac');

      // Add subtitle filter for captions
      if (captions && captions.length > 0) {
        const subtitleFilter = this.createSubtitleFilter(captions, orientation);
        if (subtitleFilter) {
          ffmpegCommand.videoFilters(subtitleFilter);
        }
      }

      ffmpegCommand
        .on('end', () => {
          logger.debug({ outputVideoPath }, "Subtitle addition complete");
          resolve(outputVideoPath);
        })
        .on('error', (error: any) => {
          logger.error(error, "Error adding subtitles to video");
          reject(error);
        })
        .save(outputVideoPath);
    });
  }

  /**
   * Create static video from image file
   */
  async createStaticVideoFromImage(
    imagePath: string,
    outputPath: string,
    duration: number,
    dimensions: string
  ): Promise<void> {
    logger.debug({ imagePath, outputPath, duration, dimensions }, "Creating static video from image");

    return new Promise((resolve, reject) => {
      ffmpeg()
        .input(imagePath)
        .inputOption('-loop 1') // Loop the image
        .inputOption(`-t ${duration}`) // Duration in seconds
        .videoCodec('libx264')
        .size(dimensions)
        .fps(30)
        .outputOption('-pix_fmt yuv420p') // Ensure compatibility
        .on('start', (commandLine) => {
          logger.debug('FFmpeg createStaticVideoFromImage command: ' + commandLine);
        })
        .on('end', () => {
          logger.debug({ outputPath }, "Static video creation complete");
          resolve();
        })
        .on('error', (error: any) => {
          logger.error(error, "Error creating static video from image");
          reject(error);
        })
        .save(outputPath);
    });
  }

  /**
   * Create static video from multiple images with different durations
   */
  async createStaticVideoFromMultipleImages(
    imageDataList: Array<{ imagePath: string; duration: number }>,
    outputPath: string,
    dimensions: string
  ): Promise<void> {
    logger.info({
      imageCount: imageDataList.length,
      outputPath,
      dimensions,
      totalDuration: imageDataList.reduce((sum, img) => sum + img.duration, 0)
    }, "Creating static video from multiple images");

    return new Promise((resolve, reject) => {
      const ffmpegCommand = ffmpeg();

      // Add each image as input with its duration
      imageDataList.forEach((imageData, index) => {
        ffmpegCommand
          .input(imageData.imagePath)
          .inputOption('-loop 1')
          .inputOption(`-t ${imageData.duration}`);
      });

      // Create filter complex for concatenation + scaling
      // Parse dimensions (e.g., "1080x1920" -> width=1080, height=1920)
      const [width, height] = dimensions.split('x').map(Number);

      const filterInputs = imageDataList.map((_, index) => `[${index}:v]`).join('');
      // Combine concat and scale in filter_complex to avoid -vf conflict
      const filterComplex = `${filterInputs}concat=n=${imageDataList.length}:v=1:a=0[concat];[concat]scale=w=${width}:h=${height}:force_original_aspect_ratio=decrease,pad=${width}:${height}:-1:-1:color=black[v]`;

      ffmpegCommand
        .complexFilter(filterComplex)
        .outputOption('-map [v]')
        .videoCodec('libx264')
        .fps(30)
        .outputOption('-pix_fmt yuv420p')
        .on('start', (commandLine) => {
          logger.debug('FFmpeg createStaticVideoFromMultipleImages command: ' + commandLine);
        })
        .on('end', () => {
          logger.info({ outputPath }, "Multi-image static video creation complete");
          resolve();
        })
        .on('error', (error: any) => {
          logger.error(error, "Error creating static video from multiple images");
          reject(error);
        })
        .save(outputPath);
    });
  }

  /**
   * Extract audio from video file to WAV format (for Whisper)
   */
  async extractAudioFromVideo(
    videoPath: string,
    outputAudioPath: string
  ): Promise<void> {
    logger.debug({ videoPath, outputAudioPath }, "Extracting audio from video");

    return new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .audioCodec('pcm_s16le')
        .audioChannels(1)
        .audioFrequency(16000)
        .toFormat('wav')
        .on('start', (commandLine) => {
          logger.debug('FFmpeg extractAudioFromVideo command: ' + commandLine);
        })
        .on('end', () => {
          logger.debug({ outputAudioPath }, "Audio extraction complete");
          resolve();
        })
        .on('error', (error: any) => {
          logger.error(error, "Error extracting audio from video");
          reject(error);
        })
        .save(outputAudioPath);
    });
  }

  /**
   * Replace video's audio track with new audio file
   * Strips VEO3's native audio and adds TTS audio
   */
  async replaceVideoAudio(
    videoPath: string,
    audioPath: string,
    outputPath: string,
    audioDuration: number
  ): Promise<void> {
    logger.debug({
      videoPath,
      audioPath,
      outputPath,
      audioDuration
    }, "Replacing video audio with TTS audio");

    return new Promise((resolve, reject) => {
      ffmpeg()
        .input(videoPath)
        .input(audioPath)
        // Strip original audio from video, use only new audio
        // Note: Removed '-shortest' because video/audio durations are already matched
        // by trimming VEO3 videos to audio length in ConsistentShortsWorkflow
        .outputOptions([
          '-map 0:v',           // Map video from first input
          '-map 1:a',           // Map audio from second input
          '-c:v copy',          // Copy video codec (no re-encoding)
          '-c:a aac',           // Encode audio to AAC
          '-strict experimental'
        ])
        .on('start', (commandLine) => {
          logger.debug('FFmpeg replaceVideoAudio command: ' + commandLine);
        })
        .on('end', () => {
          logger.info({ outputPath }, "âœ… Video audio replaced with TTS audio");
          resolve();
        })
        .on('error', (error: any) => {
          logger.error(error, "Error replacing video audio");
          reject(error);
        })
        .save(outputPath);
    });
  }
}
